run_name: ppo-llama-v3_nano-{timestamp}
output_dir: ./runs/
device: cpu
console:
  verbose: true
data:
  tokenizer_name: ./data_pipeline/processed_data/tinystories_project_vs4096.json
  prompt_data_path: ./data_pipeline/prompts/h4_prompts.txt
model:
  dim: 128
  n_layers: 4
  n_heads: 4
  n_kv_heads: 2
  vocab_size: 4096
  multiple_of: 32
  norm_eps: 1.0e-05
  max_seq_len: 256
  dropout: 0.0
  attention_variant: mha
  rope_base: 10000
  num_experts: 0
  use_activation_checkpointing: true
rl:
  algorithm: ppo
  sft_model_checkpoint: will_be_overridden
  reward_model_checkpoint: will_be_overridden
  kl_coeff: 0.02
  group_size: 1
  max_prompt_len: 32
  max_gen_len: 64
  generate:
    temperature: 0.7
    top_k: 20
  rollout_batches: 4
  update_epochs: 1
  update_batch_size: 4
  clip_epsilon: 0.2
  gamma: 0.99
  lambda_gae: 0.95
  value_loss_coef: 0.5
  entropy_coef: 0.01
training:
  batch_size: 1
  gradient_accumulation_steps: 4
  max_epochs: 1
  weight_decay: 0.0
  clip_grad_norm: 1.0
  loss_spike_threshold: 10.0
  use_activation_checkpointing: true
  learning_rate: 5.0e-07
