# FILE: configs/sft/peft/qlora/deepseek_v3_nano_qlora.yaml
# ==============================================================================
# 【SFT QLoRA 配置】 DeepSeek-V3 Nano 专用
# 验证 4-bit NF4 量化 + LoRA 在复杂架构上的运行。
# ==============================================================================

run_name: "sft-qlora-deepseek-v3-nano-{timestamp}"
output_dir: "./runs/"
device: "cpu"

console:
  verbose: true

data:
  tokenizer_name: "./data_pipeline/processed_data/tinystories_project_vs4096.json"
  sft_data_path: "./data_pipeline/processed_data/sft_data.bin"

model:
  # --- 必须与预训练模型严格一致 ---
  dim: 64
  n_layers: 2
  n_heads: 4
  vocab_size: 4096
  multiple_of: 16
  norm_eps: 1.0e-5
  max_seq_len: 128
  dropout: 0.0

  attention_variant: "mla"
  q_lora_rank: 16
  kv_lora_rank: 16
  v_head_dim: 16
  rope_head_dim: 8
  nope_head_dim: 8

  num_experts: 4
  num_shared_experts: 1
  num_experts_per_tok: 2
  use_aux_free_lb: true

sft:
  base_model_checkpoint: "will_be_overridden_by_fast_dev_run"

qlora:
  r: 16
  alpha: 32
  dropout: 0.05
  # [关键] 自动寻找所有 Linear 层进行 4-bit 量化并添加适配器
  target_modules: "auto"
  compute_dtype: "float32" # CPU 上推荐 float32

training:
  batch_size: 4
  gradient_accumulation_steps: 2
  max_epochs: 1
  learning_rate: 2.0e-4
  weight_decay: 0.0
  clip_grad_norm: 0.3
  save_interval: 100

logging:
  log_interval: 1

# END OF FILE: configs/sft/peft/qlora/deepseek_v3_nano_qlora.yaml